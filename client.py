import asyncio
import json
import os
import sys
import datetime
from typing import List
from contextlib import AsyncExitStack
from dotenv import load_dotenv

from openai import AsyncOpenAI
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

load_dotenv()

class MCPClient:
    def __init__(self):
        self.sessions: List[ClientSession] = []
        self.exit_stack = AsyncExitStack()
        self.chat_history = []
        self.report_buffer = []  # â¬… æ”¶é›†ç”¨äº Markdown æŠ¥å‘Š
        self.openai = AsyncOpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url=os.getenv("OPENAI_BASE_URL")
        )
        self.model = os.getenv("MODEL_NAME", "deepseek-chat")

    async def connect_to_servers(self, config_path: str):
        if not os.path.exists(config_path):
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_path}")
        with open(config_path, "r", encoding="utf-8") as f:
            servers = json.load(f)

        for server_source in servers:
            if server_source.endswith(".py"):
                command = "python"
                args = [server_source]
            elif server_source.endswith(".js"):
                command = "node"
                args = [server_source]
            else:
                command = "npx"
                args = ["-y", server_source]

            print(f"\nğŸ”Œ å¯åŠ¨ MCP Server: {command} {' '.join(args)}")
            server_params = StdioServerParameters(command=command, args=args, env=os.environ.copy())
            stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))
            stdio, write = stdio_transport
            session = await self.exit_stack.enter_async_context(ClientSession(stdio, write))
            await session.initialize()
            self.sessions.append(session)

        print(f"\nâœ… å·²è¿æ¥ {len(self.sessions)} ä¸ª MCP Server")

    async def collect_all_tools(self):
        tools = []
        for session in self.sessions:
            response = await session.list_tools()
            tools += [
                {
                    "type": "function",
                    "function": {
                        "name": tool.name,
                        "description": tool.description,
                        "parameters": tool.inputSchema
                    }
                }
                for tool in response.tools
            ]
        return tools

    async def call_tool(self, tool_name: str, args: dict) -> str:
        for session in self.sessions:
            response = await session.list_tools()
            if any(tool.name == tool_name for tool in response.tools):
                print(f"[DEBUG] æ­£åœ¨è°ƒç”¨ MCP å·¥å…·: {tool_name} å‚æ•°: {args}")
                result = await session.call_tool(tool_name, args)
                result_text = "\n".join(block.text for block in result.content if block.type == "text")
                return result_text
        return f"âŒ å·¥å…· {tool_name} æœªæ‰¾åˆ°"

    def save_markdown_report(self):
        folder = os.path.abspath("reports")
        os.makedirs(folder, exist_ok=True)

        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"report_{timestamp}.md"
        filepath = os.path.join(folder, filename)

        try:
            with open(filepath, "w", encoding="utf-8") as f:
                f.write("# æ¼æ´æ‰«ææŠ¥å‘Š\n\n")
                for section in self.report_buffer:
                    f.write(section + "\n\n")
            print(f"\nğŸ“„ Markdown æŠ¥å‘Šå·²ä¿å­˜:\n{filepath}")
        except Exception as e:
            print(f"\nâŒ æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")

    async def process_query(self, query: str) -> str:
        self.chat_history.append({"role": "user", "content": query})
        tools = await self.collect_all_tools()

        chat = await self.openai.chat.completions.create(
            model=self.model,
            messages=self.chat_history,
            tools=tools,
            tool_choice="auto"
        )

        reply = chat.choices[0].message
        self.chat_history.append(reply.model_dump(exclude_unset=True))

        final_texts = []
        if reply.content:
            final_texts.append(reply.content)

        tool_calls = reply.tool_calls or []
        print(f"[DEBUG] AI tool_calls: {tool_calls}")

        if not tool_calls:
            print("[INFO] AI æœªå®é™…è§¦å‘å·¥å…·è°ƒç”¨ï¼Œè·³è¿‡å·¥å…·æ‰§è¡Œé˜¶æ®µã€‚")
            if final_texts:
                self.report_buffer.append(f"## æœ€ç»ˆæ€»ç»“\n{final_texts[-1]}")
                self.save_markdown_report()
            return "\n".join(final_texts)

        for tool_call in tool_calls:
            tool_name = tool_call.function.name
            try:
                tool_args = json.loads(tool_call.function.arguments)
            except Exception as e:
                err = f"âŒ å·¥å…·å‚æ•° JSON è§£æå¤±è´¥: {e}"
                final_texts.append(err)
                continue

            result_text = await self.call_tool(tool_name, tool_args)

            self.chat_history.append({
                "role": "tool",
                "tool_call_id": tool_call.id,
                "name": tool_name,
                "content": result_text
            })

            # æ”¶é›†å·¥å…·è°ƒç”¨ç»“æœä¸º Markdown å—
            section = (
                f"## å·¥å…·ï¼š{tool_name}\n"
                f"**å‚æ•°ï¼š**\n```json\n{json.dumps(tool_args, indent=2, ensure_ascii=False)}\n```\n"
                f"**ç»“æœï¼š**\n```\n{result_text}\n```"
            )
            self.report_buffer.append(section)

        # å·¥å…·è°ƒç”¨åç»§ç»­ä¸ AI å¯¹è¯
        chat = await self.openai.chat.completions.create(
            model=self.model,
            messages=self.chat_history
        )
        next_reply = chat.choices[0].message
        self.chat_history.append(next_reply.model_dump(exclude_unset=True))

        if next_reply.content:
            final_texts.append(next_reply.content)
            self.report_buffer.append(f"## æœ€ç»ˆæ€»ç»“\n{next_reply.content}")

        # ä¿å­˜ Markdown æŠ¥å‘Š
        self.save_markdown_report()

        return "\n".join(final_texts)

    async def chat_loop(self):
        print("\nğŸ’¬ DeepSeek + MCP å®¢æˆ·ç«¯å·²å¯åŠ¨ï¼Œè¾“å…¥ä½ çš„é—®é¢˜ (è¾“å…¥ 'quit' é€€å‡º):")
        while True:
            try:
                query = input("\nä½ ï¼š").strip()
                if query.lower() == "quit":
                    break
                reply = await self.process_query(query)
                print(f"\nğŸ¤– {reply}")
            except Exception as e:
                print(f"\nâŒ é”™è¯¯: {e}")

    async def cleanup(self):
        await self.exit_stack.aclose()


async def main():
    if os.name == "nt":
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

    client = MCPClient()
    try:
        await client.connect_to_servers("mcp_server.json")
        await client.chat_loop()
    finally:
        await client.cleanup()


if __name__ == "__main__":
    asyncio.run(main())